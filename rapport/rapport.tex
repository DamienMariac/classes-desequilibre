\documentclass{article}

% Encodage et langue
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}

% Packages utiles
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{wallpaper}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[hidelinks]{hyperref}
\usepackage[backend=biber,style=numeric]{biblatex}
\addbibresource{references.bib}
\setlength{\parindent}{0pt}
\usepackage{setspace}

% Marges
%\usepackage{geometry}
%\geometry{top=2.5cm, bottom=2.5cm, left=1.8cm, right=1.8cm}
%\setstretch{1.2}

% Définir les variables (vides par défaut)
\newcommand{\UE}{}
\newcommand{\sujet}{}
\newcommand{\titre}{}
\newcommand{\enseignant}{}
\newcommand{\etudiants}{}

% Commande marges et en-têtes
\newcommand{\fairemarges}{
\pagestyle{fancy}
\fancyheadoffset{1cm}
\setlength{\headheight}{1.5cm}
\lhead{\includegraphics[scale=0.3]{images/Logo.png}}
\rhead{Labourail}
\rfoot{\thepage}
\cfoot{\textbf{\titre}}
\lfoot{\UE}
}

% Page de garde
\newcommand{\fairepagedegarde}{
\newgeometry{top=1.5cm, bottom=1.5cm, left=2cm, right=2cm}
\begin{titlepage}
\centering
\begin{center}
\begin{minipage}[c]{6cm}
    \centering
    \includegraphics[width=\linewidth, keepaspectratio]{images/Logo.png}
\end{minipage}
\hspace{1cm}
\begin{minipage}[c]{6cm}
    \centering
    \includegraphics[width=\linewidth, keepaspectratio]{images/ssd_logo_couleur_noir.png}
\end{minipage}
\end{center}
\par\vspace{0.5cm}
{\scshape\LARGE Université de Montpellier \par}
\vspace{1cm}
{\scshape\Large\sujet\par}
\vspace{0.5cm}
\rule{\linewidth}{0.5 mm} \\[0.4 cm]
{\huge\bfseries \titre \par}
\rule{\linewidth}{0.5 mm} \\[1.5 cm]
\vspace{1cm}
\begin{minipage}{0.5\textwidth}
\begin{flushleft} \large
\emph{\textbf{Étudiants:}}\\
\etudiants\\
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{\textbf{Encadrant :}} \\
\enseignant \\
\end{flushright}
\end{minipage}\\[4cm]
\vspace{0.5cm} % espace vertical avant la date
{\today}
\end{titlepage}
}


\begin{document}

% Définir les infos
\renewcommand{\UE}{UE Latex}
\renewcommand{\titre}{ Apprentissage de classes déséquilibrées}
\renewcommand{\sujet}{\LARGE HAX907X - Apprentissage statistique}
\renewcommand{\enseignant}{BENSAID Bilel}
\renewcommand{\etudiants}{SAWADOGO Kader \\ GERMAIN Marine \\ LABOURAIL Célia \\ MARIAC Damien }
% Page de garde
\fairepagedegarde

\restoregeometry

\tableofcontents

\newpage

\section{Contexte et Objectifs}

Nous nous intéressons à l’apprentissage supervisé dans des contextes où les classes sont déséquilibrées.
Ce problème est fréquent dans de nombreux domaines, tels que la détection de fraudes, la médecine ou le diagnostic industriel. Un déséquilibre important des classes peut conduire à des modèles biaisés : ils tendent à prédire correctement les classes majoritaires en négligeant les classes minoritaires.\\

La problématique scientifique que nous étudions est donc la suivante : \\
"Comment atténuer le déséquilibre de classes pour améliorer la performance des modèles ?"\\

L’objectif de ce travail est d’étudier des méthodes permettant de résoudre ce déséquilibre. Plus précisément, nous nous concentrons sur trois approches :
\begin{enumerate}
    \item Le \textbf{Random Over-Sampling} (ROS) cité dans l’article \textit{Survey on Deep Learning with Class Imbalance} \cite{johnson2019survey}, une méthode de rééchantillonage qui consiste à augmenter artificiellement la proportion de la classe minoritaire.
    \item Le \textbf{Random Under-Sampling} (RUS), une autre méthode de rééchantillonage,  cité également dans l’article \cite{johnson2019survey} qui consiste à réduire la proportion de la classe majoritaire.
    \item La \textbf{Synthetic Minority Over-sampling Technique} (SMOTE) présenté dans l’article \cite{chawla2002smote} qui génère de nouvelles instances synthétiques pour la classe minoritaire à partir des observations existantes.
\end{enumerate}


\section{Les différentes méthodes}

Les méthodes data-level agissent directement sur les données d’entraînement pour atténuer le
déséquilibre entre classes. Le principe est soit d’augmenter le poids de la classe minoritaire en lui
fournissant plus d’exemples (réels ou synthétiques), soit au contraire de réduire le poids de la classe
majoritaire en éliminant certains de ses exemples. L’objectif est d’obtenir une distribution de classes
plus équilibrée, ce qui force l’algorithme d’apprentissage à prêter autant d’attention à la minorité qu’à la
majorité. Ces techniques peuvent toutefois introduire de la variance (sur-apprentissage) ou du
biais supplémentaire, il faut donc les appliquer judicieusement.

\subsection{Sur-échantillonnage (Over-sampling)}

Le sur-échantillonnage consiste à ajouter des copies ou des variantes d'exemples de
la classe minoritaire jusqu’à augmenter sa fréquence dans le jeu de données. Dans sa forme la plus
simple, le sur-échantillonnage aléatoire ROS duplique aléatoirement des
instances minoritaires existantes jusqu’à atteindre un équilibre désiré.
\\
\\
Par exemple, si l’on dispose
de 100 exemples minoritaires et 1000 majoritaires, le ROS peut répliquer les minoritaires
(éventuellement plusieurs fois chacun) jusqu’à en obtenir 1000, rétablissant ainsi un ratio équilibré. On échantillonne avec remise parmi les indices de la classe minoritaire pour
générer de nouvelles instances d’entraînement.
\\

En revanche, la méthode présente des inconvénients. En effet, la duplication augmente le risque de surapprentissage (overfitting), car le modèle apprend alors trop précisément les exemples déjà présents dans la base de données, ce qui nuit à sa capacité à généraliser sur des nouvelles données.
De plus, la duplication de données minoritaire augmenterait significativement la taille des données ce qui implique un coût de calcul plus important.


\subsection{Sous-échantillonnage (Under-sampling)}

À l’inverse, le sous-échantillonnage vise à réduire la proportion de la classe
majoritaire en retirant certains de ses exemples du jeu de données. Le sous-échantillonnage aléatoire
RUS élimine au hasard des instances de la classe majoritaire jusqu’à atteindre
un ratio plus équilibré avec la minorité. Le RUS est utile lorsque l’on dispose d’une grande abondance de
données majoritaires, potentiellement redondantes. Plutôt que de tout utiliser, ce qui peut être
coûteux et inutile, on peut se permettre d’en élaguer une partie. En réduisant drastiquement le nombre
d’exemples majoritaires, on élimine le biais numérique et on accélère l’entraînement (moins de
données à parcourir).
\\

Selon l'article de Bee Wah Yap et al. (2013) \cite{MerwanC}, il est souvent préférable d’utiliser le RUS plutôt que le ROS, à condition que la taille du jeu de données le permette.
\\

Les deux méthodes de rééchantillonnage ROS et RUS présentent aussi certaines limites. Elles peuvent notamment conduire le modèle à croire que certaines combinaisons de variables expliquent à
elles seules la majorité des observations minoritaires, ce qui peut fausser la compréhension
réelle des relations entre variables.

\subsection{SMOTE (Synthetic Minority Over-sampling Technique)}

Plutôt que de copier des instances existantes,
SMOTE crée de nouvelles instances minoritaires artificielles en interpolant entre des exemples réels. Concrètement, pour chaque exemple minoritaire original, SMOTE sélectionne aléatoirement l’un de ses
$k$ plus proches voisins (minoritaire également), puis génère un nouvel exemple situé aléatoirement le
long du segment joignant les deux points dans l’espace des \textit{features}. En répétant ce procédé, on
peut synthétiser autant d’exemples minoritaires que souhaité.

\begin{figure}[h!]
   \centering
   \includegraphics[width=0.46\textwidth]{images/smote.png}
   \caption{Smote illustration}
   \label{fig:example}
\end{figure}

Les points bleus correspondent à la classe minoritaire dont on souhaite générer de nouveaux exemples, les points rouges sont les points générés par SMOTE.
\\
\\
Typiquement, on se place dans un espace métrique $(\mathbb{R}^d, d)$, avec la distance euclidienne (après normalisation des variables). Soit un jeu d'apprentissage
\[
\mathcal{D}=\{(x_i,y_i)\}_{i=1}^n,\quad x_i\in\mathbb{R}^d,\ y_i\in\{0,1\},
\]
et notons $\mathcal{I}_{\text{min}}=\{i:\,y_i=1\}$ l’ensemble des indices minoritaires. Pour un point minoritaire $x_i$, on note $N_k(x_i)\subset\mathcal{I}_{\text{min}}$ l’ensemble de ses $k$ plus proches voisins minoritaires selon $d$.
\\
\\
SMOTE génère un point synthétique en interpolant \emph{linéairement} entre un point minoritaire $x_i$ et un de ses voisins $x_j\in N_k(x_i)$ choisi au hasard :
\[
x_{\text{new}} \;=\; x_i \;+\; \lambda\,(x_j - x_i),
\qquad \lambda \sim \mathcal{U}(0,1).
\]
En répétant cette opération $M$ fois (réparties sur les $x_i\in\mathcal{I}_{\text{min}}$), on obtient un ensemble $\mathcal{S}$ de $M$ points synthétiques et un jeu équilibré $\mathcal{D}'=\mathcal{D}\cup\{(x,1):x\in\mathcal{S}\}$. Le nombre $M$ est fixé pour atteindre un ratio de classes cible
\[
\rho \;=\; \frac{n_{\text{min}} + M}{n_{\text{maj}}}.
\]
\\
\\
Cependant, SMOTE présente plusieurs inconvénients importants. Tout d’abord, son temps de calcul est plus long que celui des méthodes plus simples. Cela s’explique par le fait que l’algorithme doit calculer la distance
entre chaque observation minoritaire et tous les autres points pour identifier ses k plus proches voisins. Ce calcul devient rapidement coûteux lorsque la taille du jeu de données augmente, car le nombre de comparaisons croît de manière quadratique (détails en annexe \ref{sec:algo}). En pratique, cela signifie que sur des bases volumineuses ou avec beaucoup de variables, SMOTE peut nécessiter des temps de traitement bien plus élevés,
surtout lorsqu’il est utilisé à chaque étape d’une validation croisée.
\\
\\
Un autre problème souvent mentionné dans la littérature concerne la sensibilité de SMOTE aux points aberrants. Si une observation minoritaire isolée se trouve très proche d’un point appartenant à la classe majoritaire, l’algorithme risque d’utiliser cette proximité
pour créer de nouvelles données synthétiques incorrectes. Cela peut introduire du bruit et perturber l’apprentissage du modèle. Pour limiter ce problème, il est possible d’ignorer les observations minoritaires dont les k plus proches voisins appartiennent principalement
à la classe majoritaire, afin d’éviter de générer des points non représentatifs.\medskip


Plusieurs variantes de SMOTE ont été développées pour corriger ces défauts :
\begin{itemize}
    \item \textbf{SMOTE-NC (Nominal and Continuous)} : s’adapte aux jeux de données contenant à la fois des variables continues et qualitatives.
    \item \textbf{Borderline-SMOTE} (Hui Han, Wen-Yuan Wang et Bing-Huan Mao, 2005 ) : se concentre sur les points situés à la frontière entre classes, considérés comme plus informatifs pour le modèle.
\end{itemize}

\vspace{1cm}


\section{Conclusion}

Les méthodes ROS, RUS et SMOTE sont des approches différentes pour corriger le déséquilibre de classes. Elles ne se comparent pas directement, car leur efficacité dépend du jeu de données et du contexte d’application.
En effet, on voit sur le tableau \ref{tab:methode} le récapitulatif des 3 méthodes avec leur points forts et point faibles. \\
En réponse à la problématique posée, il n’existe pas de méthode réellement meilleure qu'une autre : le choix doit être adapté aux données et au modèle utilisé.
L’objectif est d’obtenir un jeu de données plus équilibré afin d’améliorer les performances du modèle.\\

\begin{table}[h!]
\centering
\begin{tabular}{|p{1.5cm}|p{4cm}|p{4.5cm}|p{4.2cm}|}
\hline

\centering
\textbf{Méthode} & \textbf{Principe} & \textbf{Avantages} & \textbf{Inconvénients} \\ \hline

\centering
ROS &
Duplication aléatoire de la classe minoritaire &
- Simplicité \newline
- Conservation des données &
- Surapprentissage \newline
- Volume important de \newline données \\ \hline


\centering
RUS &
Suppression aléatoire de la classe majoritaire &
- Rapidité \newline
- Réduction du biais \newline
- Moins de données à traiter &
- Perte d’information \newline
- Moins de représentativité \\ \hline

\centering
SMOTE &
Création d'exemples synthétiques de la classe minoritaire (interpolation entre exemples réels) &
- Données synthétiques \newline variées \newline
- Moins de surapprentissage que ROS &
- Coût calcul élevé \newline
- Sensible aux valeurs \newline abberrantes \newline
- Risque de bruit \\ \hline
\end{tabular}
\caption{Résumé des méthodes}\label{tab:methode}
\end{table}


\newpage

\section{Annexe}

\subsection{Implémentation et résultats}
\subsection*{Exemple d'application : Détection de fraudes par carte bancaire}

L’objectif de cette application est de mettre en place un modèle de détection de fraudes à partir du jeu de données \textit{Credit Card Fraud Detection} disponible sur \textit{Kaggle}.
Ce jeu contient 284\,807 transactions, dont seulement 492 sont frauduleuses (soit environ 0,17 \%).
Le fort déséquilibre entre les classes rend la tâche difficile, car un modèle naïf qui prédirait toujours ``non fraude'' atteindrait déjà un score proche de 99,8 \%.
Pour dépasser cette limite, plusieurs stratégies de gestion du déséquilibre ont été appliquées et comparées en utilisant une régression logistique.

\subsubsection*{Régression logistique sans traitement}
Dans un premier temps, nous avons entraîné le modèle sur l’ensemble complet, sans traitement particulier du déséquilibre.
Les résultats montrent une accuracy très élevée (0,9991), mais trompeuse, puisque le rappel (sensitivity) des fraudes n’est que de 0,61.
Autrement dit, la majorité des fraudes ne sont pas détectées, ce qui rend le modèle inutilisable en pratique malgré une performance apparente.

\subsubsection*{RUS}
Afin de corriger ce problème, nous avons testé le RUS, qui consiste à équilibrer les classes en réduisant volontairement le nombre de transactions normales pour égaler celui des fraudes.
Dans ce cas, le modèle obtient une \textit{balanced accuracy} d’environ 0,956 avec un rappel de 0,959.
Le modèle apprend donc à bien reconnaître les fraudes, mais au prix d’une perte importante d’information, puisque la majorité des transactions légitimes est écartée.

\subsubsection*{ROS}
La seconde approche est le ROS, qui duplique aléatoirement les fraudes afin de créer un jeu équilibré.
Cette méthode conserve toutes les données disponibles et améliore le rappel (0,977), ce qui signifie que presque toutes les fraudes sont détectées.
La \textit{balanced accuracy} atteint 0,949.
Toutefois, l’inconvénient de cette méthode est le risque de surapprentissage, car les exemples de fraude sont répétés artificiellement sans ajouter de diversité.

\subsubsection*{SMOTE}
Enfin, nous avons appliqué la méthode \textit{SMOTE (Synthetic Minority Oversampling Technique)}, qui génère artificiellement de nouveaux exemples de fraude en interpolant entre des observations existantes.
Cette méthode dépasse les performances des précédentes, avec une accuracy globale de 0,981, un rappel de 0,992 et une spécificité de 0,970.
Elle offre donc le meilleur compromis entre la détection des fraudes et la limitation des faux positifs.


\vspace{1cm}


\subsection{Algorithmes}

\begin{algorithm}[H]
\caption{RUS}
\KwIn{Dataset $D$ avec classes $C_{maj}$ et $C_{min}$}
\KwOut{Dataset équilibré $D'$}

$n_{min} \gets |C_{min}|$ \;
Sélectionner aléatoirement $n_{min}$ échantillons de $C_{maj}$\;
Construire $D' = C_{min} \cup$ sous-échantillon($C_{maj}$)\;
\Return $D'$\;
\end{algorithm}

\vspace{1cm}

\begin{algorithm}[H]
\caption{ROS}
\KwIn{Dataset $D$ avec classes $C_{maj}$ et $C_{min}$}
\KwOut{Dataset équilibré $D'$}

$n_{maj} \gets |C_{maj}|$ \;
\While{$|C_{min}| < n_{maj}$}{
   Dupliquer aléatoirement un échantillon de $C_{min}$\;
}
Construire $D' = C_{maj} \cup C_{min}$ (après duplication)\;
\Return $D'$\;
\end{algorithm}

\vspace{1cm}

\begin{algorithm}[H]
\caption{SMOTE (Synthetic Minority Over-sampling Technique)}
\KwIn{Dataset $D$ avec classes $C_{maj}$ et $C_{min}$, nombre de voisins $k$}
\KwOut{Dataset équilibré $D'$}

\ForEach{$x_i \in C_{min}$}{
   Trouver les $k$ plus proches voisins de $x_i$ dans $D$\;
   \uIf{tous les voisins appartiennent à $C_{maj}$}{
      Marquer $x_i$ comme \textbf{bruit} (non utilisé)\;
   }
   \uElseIf{la majorité des voisins appartiennent à $C_{maj}$}{
      Marquer $x_i$ comme \textbf{danger}\;
   }
   \Else{
      Marquer $x_i$ comme \textbf{safe} (non utilisé)\;
   }
}

\ForEach{$x_i$ marqué comme \textbf{danger}}{
   Sélectionner aléatoirement un voisin minoritaire $x_{voisin}$ parmi ses $k$ plus proches voisins\;
   Générer un nombre aléatoire $\lambda \sim U(0,1)$\;
   Créer un point synthétique :
   \[
      x_{\text{new}} = x_i + \lambda \cdot (x_{voisin} - x_i)
   \]
   Ajouter $x_{\text{new}}$ à $C_{min}$\;
}

Construire $D' = C_{maj} \cup C_{min}$ (avec points synthétiques générés)\;
\Return $D'$\;
\end{algorithm}

\vspace{1cm}







\subsection{Coût algorithmique}
\label{sec:algo}
On note $n$ le nombre total d'observations, $n_{\text{min}}$ le nombre d'observations minoritaires,
$d$ la dimension, $k$ le nombre de voisins à récupérer, et $M$ le nombre de points synthétiques à générer.
On suppose l’espace $\mathbb{R}^d$ standardisé et une distance euclidienne.

\paragraph{Étape kNN (dominante)} \cite{sklearnNeighbors}
\\
Pour chaque point minoritaire $x_i$, on calcule sa distance à \emph{tous} les points du jeu.
\begin{itemize}
  \item \textbf{Coût d'une distance} : $O(d)$.
  \item \textbf{Coût pour comparer à $n$ points} : $O(nd)$.
  \item \textbf{Coût pour $n_{\text{min}}$ points minoritaires} : $O(n_{\text{min}}\,n\,d)$.
\end{itemize}
La sélection des $k$ plus petites distances parmi $n$ peut se faire en temps linéaire amorti
(par sélection partielle) ou en $O(n\log n)$ via tri, mais \emph{dans tous les cas} le calcul des distances
$O(nd)$ domine lorsque $d$ et $n$ sont suffisamment grands. Ainsi, le coût de l’étape kNN en naïf est
\[
T_{\text{kNN, naïf}} = O(n_{\text{min}}\,n\,d).
\]
\vspace{0.5cm}
\textbf{Étape de génération (négligeable devant kNN)}
\\
Chaque point synthétique s’obtient par :
\[
x_{\text{new}} = x_i + \lambda\,(x_j - x_i), \qquad \lambda\sim\mathcal{U}(0,1),
\]
soit une interpolation vectorielle en $d$ composantes $\Rightarrow O(d)$ par point.
Pour $M$ points générés :
\[
T_{\text{gen}} = O(M\,d).
\]

\paragraph{Bilan temps.}
\[
\boxed{ \; T_{\text{SMOTE}} \;=\; O(n_{\text{min}}\,n\,d) \;+\; O(M\,d) \;}
\]
En pratique, le terme $O(n_{\text{min}}\,n\,d)$ (recherche des voisins par force brute) domine.

\newpage

\printbibliography

\end{document}