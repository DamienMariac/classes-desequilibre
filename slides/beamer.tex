\documentclass{beamer}

% Thème sobre et académique
\usetheme{Madrid}
\usecolortheme{seahorse}

% Langue et encodage
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{lmodern}

% Couleur personnalisée
\definecolor{c}{RGB}{120,20,30}
\setbeamercolor{title}{fg=white,bg=c}
\setbeamercolor{frametitle}{fg=white,bg=c}
\setbeamercolor{structure}{fg=c}

% Informations de la présentation
\title[Apprentissage de classes déséquilibrées]{\textbf{Apprentissage de classes déséquilibrées}}
\subtitle{\LARGE HAX907X - Apprentissage statistique}
\author[]{\textbf{SAWADOGO Kader \\ GERMAIN Marine \\ LABOURAIL Célia \\ MARIAC Damien}}
\institute[Université Montpellier]{Université Montpellier \\ Département de Mathématique}
\date{\today}

\AtBeginSection[]
{
  \begin{frame}{Sommaire}
    \tableofcontents[currentsection]
  \end{frame}
}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}
\section{Contexte}

\section{Problématique}

\begin{frame}{Les classes déséquilibrées}

    \textbf{Problème :} difficulté à prédire la classe minoritaire \\[0.3cm]
    $\Rightarrow$ Le modèle a tendance à ignorer cette classe. \\[0.5cm]

    \begin{block}{Exemple général}
        \begin{itemize}
            \item 99\% vs 1\%.
            \item Un modèle naïf prédit la classe majoritaire à une précision de 99\,\%.
            \item Mauvais modèle.
        \end{itemize}
    \end{block}

\end{frame}


\begin{frame}{Problématique scientifique}
    \centering
    \Large{Comment atténuer le déséquilibre des classes pour améliorer la performance réelle du modèle ?}
\end{frame}


\section{Méthodes}

\begin{frame}
  \frametitle{SMOTE : Synthetic Minority Over-sampling Technique}
  \begin{figure}
      \centering
      \includegraphics[width=0.7\textwidth]{images/SMOTEE.png}
      \caption{Schéma de SMOTE}
  \end{figure}

  \end{frame}

  \begin{frame}
      \frametitle{SMOTE : Synthetic Minority Over-sampling Technique}



      \begin{figure}
          \centering
          \includegraphics[width=0.7\textwidth]{images/SMOTED.png}
          \caption{Schéma de SMOTE}
      \end{figure}

  \end{frame}

  \begin{frame}
      \frametitle{SMOTE : Synthetic Minority Over-sampling Technique}



      \begin{figure}
          \centering
          \includegraphics[width=0.7\textwidth]{images/SMOTEC.png}
          \caption{Schéma de SMOTE}
      \end{figure}

  \end{frame}

  \begin{frame}
      \frametitle{SMOTE : Synthetic Minority Over-sampling Technique}



      \begin{figure}
          \centering
          \includegraphics[width=0.7\textwidth]{images/SMOTEB.png}
          \caption{Schéma de SMOTE}
      \end{figure}

  \end{frame}

  \begin{frame}
      \frametitle{SMOTE : Synthetic Minority Over-sampling Technique}



      \begin{figure}
          \centering
          \includegraphics[width=0.7\textwidth]{images/SMOTEA.png}
          \caption{Schéma de SMOTE}
      \end{figure}

  \end{frame}






  \begin{frame}[t,shrink=8]{SMOTE : Synthetic Minority Over-sampling Technique}

    \begin{block}{Notations}
    \footnotesize
    \begin{columns}[T,totalwidth=\textwidth]
      \column{0.52\textwidth}
      \begin{itemize}
        \setlength{\itemsep}{1pt}\setlength{\parskip}{0pt}
        \item $n$ : nb \textbf{total} d'observations
        \item $n_{\min}$ : nb d'observations \textbf{minoritaires}
        \item $d$ : dimension (nb de variables)
      \end{itemize}
      \column{0.48\textwidth}
      \begin{itemize}
        \setlength{\itemsep}{1pt}\setlength{\parskip}{0pt}
        \item $k$ : nb de plus proches voisins
        \item $M$ : nb de points synthétiques générés
      \end{itemize}
    \end{columns}
    \end{block}

    \begin{block}{Étapes dominantes \& complexité (naïf)}
    \footnotesize
    \begin{enumerate}
      \setlength{\itemsep}{2pt}\setlength{\parskip}{0pt}
      \item \textbf{Recherche des $k$-PPV (vers tous les points)} :
            coût d'une distance $\mathcal O(d)$ $\Rightarrow$
            comparaison à $n$ points $\mathcal O(n\,d)$ $\Rightarrow$
            pour $n_{\min}$ points minoritaires $\boxed{\mathcal O(n_{\min}\,n\,d)}$.
      \item \textbf{Génération} :
            $x_{\text{new}} = x_i + \lambda(x_j-x_i)$, $\lambda\sim\mathcal U(0,1)$
            \hfill $\boxed{\mathcal O(M\,d)}$
    \end{enumerate}
    \end{block}

    \begin{block}{Synthèse}
    \footnotesize
    \[
    \boxed{T_{\text{SMOTE}}=\mathcal O(n_{\min}\,n\,d) + \mathcal O(M\,d)}
    \quad\text{(recherche kNN dominante).}
    \]
    \end{block}

  \end{frame}

\section{Limites des méthodes}


\section{Application}


\section{Conclusion}

\begin{frame}{Bilan général des méthodes}
    \centering
    \small
    \begin{tabular}{|l|p{3cm}|p{3cm}|}
        \hline
        \centering
        \textbf{Méthode} & \textbf{Points forts} & \textbf{Limites} \\
        \hline
        \centering
        ROS & Simplicité, conserve toutes les données & Overfitting, grand volume de données \\
        \hline
        \centering
        RUS & Rapide et réduit le biais & perte d'information et représentativité \\
        \hline
        \centering
        SMOTE & Données synthétiques variées & Coût élevé, sensible aux outliers \\
        \hline
    \end{tabular}
    \vspace{0.7cm}

    \textbf{Aucune méthode n’est universelle :}\\
    le choix dépend du jeu de données et du modèle.
\end{frame}

\begin{frame}{Conclusion et perspectives}
    \begin{itemize}
        \item Pour notre jeu de données, la méthode la plus efficace est SMOTE.\\[0.5cm]
        \item  Pour aller plus loin : il serait pertinent de combiner des méthodes existantes ou de pondérer les modèles.
    \end{itemize}
\end{frame}

\begin{frame}
    \centering
    \Huge Merci pour votre attention !
\end{frame}

\end{document}